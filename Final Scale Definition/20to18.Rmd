---
title             : "20 to 18 - Final Scale Definitions of the Bifactor Engagement Scale"
shorttitle        : "20 to 18"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  We finalize the scale definitions for a bifactor engagement measure that is comprised of intentionally complex items. 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, warning=FALSE, echo=FALSE)
```



# Methods

## Participants

```{r getdata}

## Original script is "combined samples.R" in this folder

## Cleaning Qualtrics construct validation data - 10/14/21
## apparently different working paths for rmarkdown: https://here.r-lib.org/

newdata.att <- read.csv("..//Qualtrics//Engagement+(Attitudinal)_October+12,+2021_08.02.csv"); names <- newdata.att[1,c(1:92)] #[47:66]
newdata.sub <- read.csv("..//Qualtrics//Engagement+(Substantive)_October+12,+2021_08.01.csv")#[47:66]

newdata.att <- newdata.att[-c(1:2),]                      ## peskies
newdata.sub <- newdata.sub[-c(1:2),]

write.csv(newdata.att, "changingnumerica.csv")
newdata.att <- read.csv("changingnumerica.csv")            ## that worked!! 
write.csv(newdata.sub, "changingnumerics.csv")
newdata.sub <- read.csv("changingnumerics.csv") 

library(careless)
newdata.att$careless_long <- longstring(newdata.att[20:83])
newdata.sub$careless_long <- longstring(newdata.sub[20:83])
newdata.att$irv <- irv(newdata.att[48:51])
newdata.sub$irv <- irv(newdata.sub[55:58])

newdata.att$irv2 <- irv(newdata.att[25:28])   ## another reverse-score
newdata.sub$irv2 <- irv(newdata.sub[25:28])

## need filter for non-differentiating reverse-score people

newdata.att$flag <- "use"; newdata.sub$flag <- "use"         ## need to do because subset on lines 44/45 can't != "Flagged"
## upped time to 300 seconds as data still looked bad with 200

newdata.att$flag[newdata.att$careless_long > 12 | newdata.att$Duration..in.seconds. < 300 | newdata.att$irv == 0 | newdata.att$irv2 == 0]  <- "Flagged"
newdata.sub$flag[newdata.sub$careless_long > 12 | newdata.sub$Duration..in.seconds. < 300 | newdata.sub$irv == 0 | newdata.sub$irv2 == 0]  <- "Flagged"

newdata.att$flag <- as.factor(newdata.att$flag)
newdata.sub$flag <- as.factor(newdata.sub$flag)


useatt <- newdata.att[ which(newdata.att$flag == "use"), c(1:92)]
usesub <- newdata.sub[ which(newdata.sub$flag == "use"), c(1:92)]

useseb.sorted <- usesub[,c(1:47, 48:50,55:56,61:63,51:52,57:58,64:65,53:54,59:60,66:67,68:92)]
names(useseb.sorted) <- names(useatt)           ##### focal engagement is 48:67

qualtrics <- as.data.frame(rbind(useseb.sorted,useatt))      ## 377 out of 743 (51% retained)
                                                             ## engagement = 48-67
qualtrics.engage <- qualtrics[,c(48:67)]

qualtrics.engage <- data.frame(lapply(qualtrics.engage, function(x) as.numeric(as.character(x))))

################################################################################
################################################################################
################################################################################
################################################################################

## Prolific:    

temp <- read.csv("..//prolific data//initial_data_screen.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

x <- paste("item", sep="",1:404)
y <- t(temp[2,])
## decluttering Qualtrics excess
data <- temp[-c(1:3),]                                           ## Getting rid of all 3 weird Qualtrics rows
colnames(data) <- x

incomplete <- read.csv("..//prolific data//inprogress.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

data2 <- incomplete[-c(1:2),-c(10,12,16,113,199,285,371,379,400, 406:411)]                                          

data3 <- as.data.frame(cbind(data2$V8,data2$V9,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2))

colnames(data3) <- x

rm(x, y, temp)       

use <- rbind(data,data3)

## STILL NEED FILE WITH BAD RESPONDENTS IDENTIFIED (E.G., Item_18=2, na > 200, longstring > 20, CARELESS CHECKS > 1)

library(careless)
use$careless_long <- longstring(use[18:399])
use$missing <- rowSums(is.na(use[18:404])) 

use$flag <- NA

use$flag[use$item18 == 2 | use$careless_long > 20 | use$missing > 200] <- "Flagged"
use$flag[use$item61 == 5 & use$item145 == 5 & use$item248 == 2 & use$item308 == 3] <- "Good"

use2 <- use[which(use$flag == "Good"), ]
## descr::freq(use2$flag)                         ## no overlap - all "good" unflagged


prolific <- use2[,c(380:382,387:388,393:395,
                    383:384,389:390,396:397,
                    385:386,391:392,398:399)]     ## 568 out of 785 (72% retained)

names(prolific) <- names(qualtrics.engage)
prolific <- data.frame(lapply(prolific, function(x) as.numeric(as.character(x))))

######################################################################################################
######################################################################################################
######################################################################################################


## The sample was expanded via further snowball sampling with Eagle newbies on/about March 2022, with the additional sample (n=232; "Engagement(post-Qualtrics)April1920221118.csv")
## The current sample has 234 using choice text from Engagement_Pos Qual_2022-05-01_Choic Text.csv. Was pulled on May 1, 2022. 

snowball <- read.csv("..//Snowball Data//Engagement_Pos Qual_2022-05-01_Numeric Text.csv")[-c(1:2),c(47:66)]

snowball <- data.frame(lapply(snowball, function(x) as.numeric(as.character(x))))

##########################################################################
##########################################################################
##########################################################################

prolific$from <- "Prolific"
snowball$from <- "Snowball"
qualtrics.engage$from <- "Qualtrics"

together <- rbind(prolific, snowball, qualtrics.engage)

```

Of the `r (nrow(newdata.att)+nrow(newdata.sub))` total Qualtrics panel respondents, `r (nrow(newdata.att)+nrow(newdata.sub))-(nrow(qualtrics.engage))` were excluded based on conservative indices of carelessness across the larger survey (consistent non-differentiating responses across more than 20 consecutive items or greater than 50% missing responses. For Prolific panel respondents, `r nrow(prolific)` were retained of `r nrow(use)` total participants due to the same exclusion criteria. The smaller (*n* = `r nrow(snowball)`) snowball sample retained all participants for a total combined analysis sample of `r nrow(together)`.

## Material



## Procedure

A previous instrument administration reduced 36 candidate items to 20. Primarily for reason of equal balance, we wanted to ultimately land on 18 items (6 per attitudinal/substantive scale dimension, 2 per bifactor subscale). Two primary considerations were given to the decision to retain or delete the 6 deletion candidates: 1) is the content of the item necessary for the definitional content domain, and 2) does the empirical functioning of the item implicate possible revision/deletion. The items considered deletion candidates were from the Absorption-Cognition subscale (Item 1: *I am able to concentrate on my work without getting distracted*, Item 3: *Time passes quickly while I'm working*, and Item 4: *I find it difficult to mentally disconnect from work*) and the Dedication-Cognition subscale (Item 25: *I plan to stay with this company as my career advances*, Item 26: *I believe this company cares about my career goals*, and Item 28: *This organization challenges me to work at my full potential*).

## Data analysis

We used `r cite_r("r-references.bib")` for all our analyses. 


```{r scalereduction, fig.cap="Bifactor analysis minus Item 4."}

## Drop candidates are 1,3,4 & 25,26,28

together$C14 <- 7-together$C14

cog <- psych::alpha(together[1:8])
aff <- psych::alpha(together[9:14])
beh <- psych::alpha(together[15:20])

abs <- psych::alpha(together[c(1:3, 9:10, 15:16)])
vig <- psych::alpha(together[c(4:5, 11:12, 17:18)])
ded <- psych::alpha(together[c(6:8, 13:14, 19:20)])

# cor(together[1:8], use="pairwise.complete.obs")   ## probably C4 gets axed
# psych::alpha(together[1:3])

# cor(together[c(1:3, 9:10, 15:16)], use="pairwise.complete.obs")


library(lavaan)

bifactor1 <-'
Absorption = ~C1  + C3  + C4  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C4  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

bifactor4 <-'
Absorption = ~C1  + C3  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

Fit.mod1 <- lavaan::cfa(bifactor1, data = together, missing = "ML", estimator = 'MLR')
Fit.mod4 <- lavaan::cfa(bifactor4, data = together, missing = "ML", estimator = 'MLR')

# semPlot::semPaths(Fit.mod2, bifactor = c("Cognitive", "Affective", "Behavioral"), "std", layout = "tree3",
#                  rotation = 2, curvePivot=TRUE, style="lisrel", nCharNodes = 0, pastel=FALSE)

semPlot::semPaths(Fit.mod4, bifactor = c("Cognitive", "Affective", "Behavioral"), style="lisrel", "std", layout = "tree3", rainbowStart=.5,sizeLat=10, rotation = 2, sizeMan=4.5,edge.label.cex=0.75, asize=2)

stand1 <- standardizedSolution(Fit.mod1)
fit1 <- fitMeasures(Fit.mod1)

stand4 <- standardizedSolution(Fit.mod4)
fit4 <- fitMeasures(Fit.mod4)

```

Looking first at the Absorption-Cognition candidate items, Item 4 stood out as a candidate for exclusion based on empirical indices (corrected item-total correlations, inter-item correlations, and bifactor analysis fit [$\chi^2_{with}$ = `r fit1[3]`, $\chi^2_{without}$ = `r fit4[3]`]). Conceptually we also agreed that Item 4 was not uniquely critical for comprehensive coverage across either the Cognition or Absorption constructs. Figure \@ref(fig:scalereduction) presents the visual CFA.

# Results

```{r itemstable}

items <- read.csv("modification indices KEY - Hopefully Final.csv")  ## without 4

apa_table(
  items
  , caption = "Suggested final scale definitions."
  , escape = TRUE
  , landscape = TRUE
)

```


The final recommended scale definitions are located in Table \@ref(tab:itemstable). 

# Discussion


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
