---
title             : "20 to 18 - Final Scale Definitions of the Bifactor Engagement Scale"
shorttitle        : "20 to 18"

author: 
  - name          : "Mike DeFabiis"
    affiliation   : "1"
    corresponding : yes    # Define only one 
  - name          : "Casey Osorio"
    affiliation   : "2"
  - name          : "Morgan Russell"
    affiliation   : "1"
  - name          : "John Kulas"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Montclair State University"
  - id            : "2"
    institution   : "Harver"
  - id            : "3"
    institution   : "eRg"
authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  We finalize the scale definitions for a bifactor engagement measure that is comprised of intentionally complex items. 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "siop.bib"]

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, warning=FALSE, echo=FALSE)
```


The roots of employee [aka work; e.g., @schaufeli_conceptualization_2010] engagement research likely started with theoretical expansions of forms of employee participation [see, for example, @ferris_added_1984] and job involvement [e.g., @elloy_examination_1991]. This exploration extended into broader considerations of attitudes and emotions [@staw_employee_1994] and were informed by further exploration of the dimensionality of constructs such as organizational commitment [@meyer_three-component_1991]. The 1990's saw focused development and refinement [for example, a dissertation; @leone_relation_1995 or actual semantic reference; @kahn_psychological_1990]. @staw_employee_1994 investigated the relationships between *positive emotions* and favorable work outcomes, and although they do not use the word, "engagement", their distinction between felt and expressed emotion likely held influence upon the burgeoning interest in the engagement construct.

Clear in this history is the specification of engagement as a work *attitude*.

Although occasionally referred to as residing on the opposing pole to *burnout* [@maslach_early_2008], these two constructs are currently most commonly conceptualized as being distinct [@timms2012burnt; @kim_burnout_2009; @goering2017not; @schaufeli2008workaholism], although certainly not universally [@cole2012job; @taris2017burnout]. Comparing the two, @goering2017not concluded that they have a moderate (negative) association, but also distinct nomological networks. @schaufeli2008workaholism investigated both internal and external association indicators, concluding that engagement and burnout (as well as *workaholism*) should be considered three distinct constructs. 

Burnout can be defined as a psychological syndrome characterized by exhaustion (low energy), cynicism (low involvement), and inefficacy (low self-efficacy), which is experienced in response to chronic job stressors [e.g., @leiter_areas_2004; @maslach1997causes]. Alternatively, engagement refers to an individual worker's involvement and satisfaction as well as enthusiasm for work [@harter_business-unit-level_2002]. @schaufeli_uwesutrecht_2003 further specify a "positive, fulfilling, work-related state of mind that is characterized by vigor, dedication, and absorption" (p. 74). Via their conceptualization, vigor is described as high levels of energy and mental resilience while working. Dedication refers to being strongly involved in one's work and experiencing a sense of significance, enthusiasm, inspiration, pride, and challenge. Absorption is characterized by being fully concentrated and happily engrossed in one's work, whereby time passes quickly and one has difficulties with detaching oneself from work [@schaufeli_measurement_2002]. The dimension of absorption has been noted as being influenced in conceptual specification by [@csikszentmihalyi1990flow]'s concept of "flow".

Regarding measurement, Gallup is widely acknowledged as an early pioneer in the measurement of the construct [see, for example, @coffman_hard_1999]. The Utrecht Work Engagement Scale (UWES) is another self-report questionnaire developed by @schaufeli_uwesutrecht_2003 that directly assesses the vigor, dedication, and absorption elements.

## Attitudes 

> TRIPARTITE MODEL--work here

The first, to our knowledge, use of the word "engagement" as a construct came in @kahn1990psychological, defining it as: "the harnessing of organization members' selves to their work roles; in engagement, people employ and express themselves physically, cognitively, and emotionally during role performances." Although this definition was quickly bypassed by subsequent papers (see, for example, [@baumruk2004missing] and [@shaw2005engagement], who framed it in terms of one's cognitive and affective *commitment* to one's organization), @kahn1990psychological's definition is notable in that it conforms to the then-ascendant tripartite model of attitudes proposed by @rosenberg_cognitive_1960. This model frames attitudes as latent variables that manifest cognitively, affectively and behaviorally.

Although falling out of favor in the decades following its construction, interest in the tripartite model was revived by @kaiser_campbell_2019,


The present article explores two methods for constructing a scale that incorporates both the substantive and attitudinal models into one, a more classical one based on corrected item-total correlations and one based on modification indices.

# Existing measures include @soane2012development

Multiple measures of engagement currently exist, with one notable measure being the Intellectual, Social, Affective (ISA) Engagement Scale [@soane2012development]. This 9-item measure draws inspiration from @kahn_psychological_1990's theory towards engagement, primarily utilizing his notion that an individual’s work role demonstrates a focus for engagement. In the ISA Engagement Scale, the focused role is accompanied by activation and positive affect. Together, these components result in three facets in @soane2012development's multidimensional model: Intellectual Engagement, Social Engagement, and Affective Engagement. Intellectual engagement is defined as 'the extent to which one is intellectually absorbed in work and thinks about ways to improve work' [@soane2012development]. Social engagement primarily concerns social connections at work as well as shared values, as @soane2012development defines it as 'the extent to which one is socially connected with the working environment and shares common values with colleagues'. Affective engagement refers to 'the extent to which one experiences a state of positive affect relating to one's work role'. Together these three facets comprise ISA engagement. This is the first known measure of engagement that is validated at both the facet and factor level, having validated both ISA engagement and its three facets [@soane2012development]. 

Another example of an engagement measure comes from @saks_antecedents_2006, who splits engagement into two distinct entities: job engagement and organization engagement. This dichotomy largely results from @kahn_psychological_1990’s theory that an individual’s role is central to engagement. @saks_antecedents_2006 believes that employees typically have more than one role, with the most important being their work role and their role as a member of an organization. The former role is specific to the employee’s job, while the latter is more broad and refers to the organization as a whole. Antecedents and consequences of employee engagement were also tested, with findings suggesting that perceived organizational support precedes both job and organizational engagement and that job satisfaction, organizational commitment, intent to quit, and organizational citizenship behaviors (OCBs) at the individual and organization level are outcomes of high and low levels of engagement. Recently the model was revisited and revised to include several new antecedents (e.g. leadership, job demands, dispositional characteristics, etc.) leading to engagement as well as consequences (e.g. burnout, stress, health and well-being, etc.) resulting from high or low levels of engagement [@saks2019antecedents].

Gallup’s Q12 is one of the more popular measures for engagement. The Q12 is a 12-item measure that originated from a push to use “soft” metrics as opposed to “hard” ones for future action planning [@coffman_hard_1999]. In this interpretation “soft” metrics tend to be metrics that are more abstract and difficult to measure (e.g. engagement, brand loyalty), while “hard” metrics are easily-measured metrics that typically deal with concrete numbers (e.g. turnover, profitability). In the original creation of the survey, each of the 12 items were found to relate to important organizational outcomes including productivity, profitability, turnover, and customer satisfaction [@coffman_hard_1999]. A recent meta-analysis of 456 studies revealed that the Q12 relates also to additional performance measures such as absenteeism, wellbeing, and organizational citizenship [@harter_relationship_2013]. While this engagement measure is one of the most popular, some scholars disagree with its conceptualization as “engagement”; some feel that this measure is better described as (or no different than) a measure of overall satisfaction, as the two concepts are highly correlated, *r* = .91 [@sirota2013enthusiastic]. 

Gallup is not the only organization with an engagement measure; many consulting companies have commercially available surveys, models, and processes for measuring engagement. One such example is Aon Hewitt, a consulting firm that annually measures engagement for over 1000 companies worldwide. Their measurements are centered around an engagement model that focuses on three main factors: say, stay, and strive. Essentially, the model states that employees demonstrate engagement through saying positive statements about their organization, staying at their organization for a long time, and striving to put in their best effort and help the organization succeed [@hewitt2017]. In their most recent analysis. @hewitt2017 found that global levels of engagement had retracted since the previous year.

BlessingWhite, another consulting firm, provides a different model for engagement. BlessngWhites model, the X Model, measures engagement through the lens of satisfaction and contribution. Essentially, BlessingWhite believes that cooperation between the organization and individual employees is necessary, and that maximum engagement can only be reached when an employee reachings maximum levels of satisfaction while also outputting maximum contribution towards the organization [@blessingwhite2018]. Their model holds each level in the organization accountable for employee levels of engagement. From their view, executive leaders must shape the organization's culture, and managers must be able to effectively communicate with and motivate their subordinates [@blessingwhite2018]. 



Our conceptualization of work engagement is a mental state wherein employees: a) feel energized (*Vigor*), b) are enthusiastic about the content of their work and the things they do (*Dedication*), and c) are so immersed in their work activities that time seems compressed (*Absorption*). We further decompose each of these facets into three attitudinal components: d) feeling (e.g., affect), e) thought (e.g., cognition), and f) action (e.g., behavior). Development and construct validation of the focal 18-item measure of engagement is described in @engage_2022 whereas the current study on administrative response cues in the form of order of item presentation. The expectation is that either model (attitudinal or substantive) will exhibit stronger factorial validity when item administration parallels latent structure.

Our contributions:

1. Methodological
  + Intentional bi-factor structure
2. Practical
  + A new public domain measure of engagement
  + Scalable to two aggregations (research [DAC] and actionable [ABC])
3. Theoretical
  + Possibly help explain some of the high inter-scale correlations reported with other measures 

# Methods

## Participants

```{r getdata}

## Original script is "combined samples.R" in this folder

## Cleaning Qualtrics construct validation data - 10/14/21
## apparently different working paths for rmarkdown: https://here.r-lib.org/

newdata.att <- read.csv("..//Qualtrics//Engagement+(Attitudinal)_October+12,+2021_08.02.csv"); names <- newdata.att[1,c(1:92)] #[47:66]
newdata.sub <- read.csv("..//Qualtrics//Engagement+(Substantive)_October+12,+2021_08.01.csv")#[47:66]

newdata.att <- newdata.att[-c(1:2),]                      ## peskies
newdata.sub <- newdata.sub[-c(1:2),]

write.csv(newdata.att, "changingnumerica.csv")
newdata.att <- read.csv("changingnumerica.csv")            ## that worked!! 
write.csv(newdata.sub, "changingnumerics.csv")
newdata.sub <- read.csv("changingnumerics.csv") 

library(careless)
newdata.att$careless_long <- longstring(newdata.att[20:83])
newdata.sub$careless_long <- longstring(newdata.sub[20:83])
newdata.att$irv <- irv(newdata.att[48:51])
newdata.sub$irv <- irv(newdata.sub[55:58])

newdata.att$irv2 <- irv(newdata.att[25:28])   ## another reverse-score
newdata.sub$irv2 <- irv(newdata.sub[25:28])

## need filter for non-differentiating reverse-score people

newdata.att$flag <- "use"; newdata.sub$flag <- "use"         ## need to do because subset on lines 44/45 can't != "Flagged"
## upped time to 300 seconds as data still looked bad with 200

newdata.att$flag[newdata.att$careless_long > 12 | newdata.att$Duration..in.seconds. < 300 | newdata.att$irv == 0 | newdata.att$irv2 == 0]  <- "Flagged"
newdata.sub$flag[newdata.sub$careless_long > 12 | newdata.sub$Duration..in.seconds. < 300 | newdata.sub$irv == 0 | newdata.sub$irv2 == 0]  <- "Flagged"

newdata.att$flag <- as.factor(newdata.att$flag)
newdata.sub$flag <- as.factor(newdata.sub$flag)


useatt <- newdata.att[ which(newdata.att$flag == "use"), c(1:92)]
usesub <- newdata.sub[ which(newdata.sub$flag == "use"), c(1:92)]

useseb.sorted <- usesub[,c(1:47, 48:50,55:56,61:63,51:52,57:58,64:65,53:54,59:60,66:67,68:92)]
names(useseb.sorted) <- names(useatt)           ##### focal engagement is 48:67

qualtrics <- as.data.frame(rbind(useseb.sorted,useatt))      ## 377 out of 743 (51% retained)
                                                             ## engagement = 48-67
qualtrics.engage <- qualtrics[,c(48:67)]

qualtrics.engage <- data.frame(lapply(qualtrics.engage, function(x) as.numeric(as.character(x))))

################################################################################
################################################################################
################################################################################
################################################################################

## Prolific:    

temp <- read.csv("..//prolific data//initial_data_screen.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

x <- paste("item", sep="",1:404)
y <- t(temp[2,])
## decluttering Qualtrics excess
data <- temp[-c(1:3),]                                           ## Getting rid of all 3 weird Qualtrics rows
colnames(data) <- x

incomplete <- read.csv("..//prolific data//inprogress.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

data2 <- incomplete[-c(1:2),-c(10,12,16,113,199,285,371,379,400, 406:411)]                                          

data3 <- as.data.frame(cbind(data2$V8,data2$V9,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2))

colnames(data3) <- x

rm(x, y, temp)       

use <- rbind(data,data3)

## STILL NEED FILE WITH BAD RESPONDENTS IDENTIFIED (E.G., Item_18=2, na > 200, longstring > 20, CARELESS CHECKS > 1)

library(careless)
use$careless_long <- longstring(use[18:399])
use$missing <- rowSums(is.na(use[18:404])) 

use$flag <- NA

use$flag[use$item18 == 2 | use$careless_long > 20 | use$missing > 200] <- "Flagged"
use$flag[use$item61 == 5 & use$item145 == 5 & use$item248 == 2 & use$item308 == 3] <- "Good"

use2 <- use[which(use$flag == "Good"), ]
## descr::freq(use2$flag)                         ## no overlap - all "good" unflagged


prolific <- use2[,c(380:382,387:388,393:395,
                    383:384,389:390,396:397,
                    385:386,391:392,398:399)]     ## 568 out of 785 (72% retained)

names(prolific) <- names(qualtrics.engage)
prolific <- data.frame(lapply(prolific, function(x) as.numeric(as.character(x))))

######################################################################################################
######################################################################################################
######################################################################################################


## The sample was expanded via further snowball sampling with Eagle newbies on/about March 2022, with the additional sample (n=232; "Engagement(post-Qualtrics)April1920221118.csv")
## The current sample has 234 using choice text from Engagement_Pos Qual_2022-05-01_Choic Text.csv. Was pulled on May 1, 2022. 

snowball <- read.csv("..//Snowball Data//Engagement_Pos Qual_2022-05-01_Numeric Text.csv")[-c(1:2),c(47:66)]

snowball <- data.frame(lapply(snowball, function(x) as.numeric(as.character(x))))

##########################################################################
##########################################################################
##########################################################################

prolific$from <- "Prolific"
snowball$from <- "Snowball"
qualtrics.engage$from <- "Qualtrics"

together <- rbind(prolific, snowball, qualtrics.engage)

```

Of the `r (nrow(newdata.att)+nrow(newdata.sub))` total Qualtrics panel respondents, `r (nrow(newdata.att)+nrow(newdata.sub))-(nrow(qualtrics.engage))` were excluded based on conservative indices of carelessness across the larger survey (consistent non-differentiating responses across more than 20 consecutive items or greater than 50% missing responses. For Prolific panel respondents, `r nrow(prolific)` were retained of `r nrow(use)` total participants due to the same exclusion criteria. The smaller (*n* = `r nrow(snowball)`) snowball sample retained all participants for a total combined analysis sample of `r nrow(together)`.

## Material



## Procedure

A previous instrument administration reduced 36 candidate items to 20. Primarily for reason of equal balance, we wanted to ultimately land on 18 items (6 per attitudinal/substantive scale dimension, 2 per bifactor subscale). Two primary considerations were given to the decision to retain or delete the 6 deletion candidates: 1) is the content of the item necessary for the definitional content domain, and 2) does the empirical functioning of the item implicate possible revision/deletion. The items considered deletion candidates were from the Absorption-Cognition subscale (Item 1: *I am able to concentrate on my work without getting distracted*, Item 3: *Time passes quickly while I'm working*, and Item 4: *I find it difficult to mentally disconnect from work*) and the Dedication-Cognition subscale (Item 25: *I plan to stay with this company as my career advances*, Item 26: *I believe this company cares about my career goals*, and Item 28: *This organization challenges me to work at my full potential*).

## Data analysis

We used `r cite_r("r-references.bib")` for all our analyses. 


```{r scalereduction, fig.cap="Bifactor analysis minus Item 4."}

## Drop candidates are 1,3,4 & 25,26,28

together$C14 <- 7-together$C14

cog <- psych::alpha(together[1:8])
aff <- psych::alpha(together[9:14])
beh <- psych::alpha(together[15:20])

abs <- psych::alpha(together[c(1:3, 9:10, 15:16)])
vig <- psych::alpha(together[c(4:5, 11:12, 17:18)])
ded <- psych::alpha(together[c(6:8, 13:14, 19:20)])

# cor(together[1:8], use="pairwise.complete.obs")   ## probably C4 gets axed
# psych::alpha(together[1:3])

# cor(together[c(1:3, 9:10, 15:16)], use="pairwise.complete.obs")


library(lavaan)

bifactor1 <-'
Absorption = ~C1  + C3  + C4  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C4  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

bifactor4 <-'
Absorption = ~C1  + C3  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

Fit.mod1 <- lavaan::cfa(bifactor1, data = together, missing = "ML", estimator = 'MLR')
Fit.mod4 <- lavaan::cfa(bifactor4, data = together, missing = "ML", estimator = 'MLR')

# semPlot::semPaths(Fit.mod2, bifactor = c("Cognitive", "Affective", "Behavioral"), "std", layout = "tree3",
#                  rotation = 2, curvePivot=TRUE, style="lisrel", nCharNodes = 0, pastel=FALSE)

semPlot::semPaths(Fit.mod4, bifactor = c("Cognitive", "Affective", "Behavioral"), style="lisrel", "std", layout = "tree3", rainbowStart=.5,sizeLat=10, rotation = 2, sizeMan=4.5,edge.label.cex=0.75, asize=2)

stand1 <- standardizedSolution(Fit.mod1)
fit1 <- fitMeasures(Fit.mod1)

stand4 <- standardizedSolution(Fit.mod4)
fit4 <- fitMeasures(Fit.mod4)

```

Looking first at the Absorption-Cognition candidate items, Item 4 stood out as a candidate for exclusion based on empirical indices (corrected item-total correlations, inter-item correlations, and bifactor analysis fit [$\chi^2_{with}$ = `r fit1[3]`, $\chi^2_{without}$ = `r fit4[3]`]). Conceptually we also agreed that Item 4 was not uniquely critical for comprehensive coverage across either the Cognition or Absorption constructs. Figure \@ref(fig:scalereduction) presents the visual CFA.

# Results

```{r itemstable}

items <- read.csv("modification indices KEY - Hopefully Final.csv")  ## without 4

apa_table(
  items
  , caption = "Suggested final scale definitions."
  , escape = TRUE
  , landscape = TRUE
)

```


The final recommended scale definitions are located in Table \@ref(tab:itemstable). 

# Discussion


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
