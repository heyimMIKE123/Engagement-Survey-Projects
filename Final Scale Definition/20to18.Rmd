---
title             : "20 to 18 - Final Scale Definitions of the Bifactor Engagement Scale"
shorttitle        : "20 to 18"

author: 
  - name          : "Mike DeFabiis"
    affiliation   : "1"
    corresponding : yes    # Define only one
    address       : "1313 Mockingbird Lane"
    email         : "defabiism1@montclair.edu" 
  - name          : "Casey Osorio"
    affiliation   : "2"
  - name          : "John Kulas"
    affiliation   : "3"
  - name          : "Morgan Russell"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Montclair State University"
  - id            : "2"
    institution   : "Harver"
  - id            : "3"
    institution   : "eRg"
authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  We finalize the scale definitions for a bifactor engagement measure that is comprised of intentionally complex items. This complexity crosses attitudinal and substantive components. The final scale definition exhibited moderately good bifactor fit, and the final version of the instrument allows aggregations that should be desirable for both researchers (substantive) as well as practitioners (attitude). 
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "siop.bib"]

floatsintext      : no
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

csl               : "apa7.csl"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, warning=FALSE, echo=FALSE)
```


The origins of research on employee engagement began with theoretical expansions on forms of employee participation [see, for example, @ferris_added_1984] and job involvement [e.g., @elloy_examination_1991]. Over a period of time, research and theory expanded into broader considerations of attitudes and emotions [@staw_employee_1994] and were further informed by discoveries regarding the dimensionality of nomologically adjacent constructs such as organizational commitment [@meyer_three-component_1991]. The 1990's was a time of expanding interest and exploration. For example, @leone_relation_1995 conducted a dissertation and @kahn1990psychological popularized the wide-spread semantic use of the construct label, "engagement". 

The surging interest inevitably resulted in multiple differing perspectives regarding engagement. Some viewed engagement from a globally evaluative perspective [@staw_employee_1994; @kahn1990psychological], while others approached its study by deconstructing the construct's content domain specification [@schaufeli_measurement_2002]. @schaufeli2013engagement stated a preference for the label "work engagement" rather than referring to the construct as "employee engagement", arguing that the "employee" referrent perhaps invites a blurring of definitions with other conceptually similar constructs such as commitment or organizational citizenship. @maslach_early_2008 proposed that engagement and burnout[^burn] [@maslach1997causes] are direct opposites of each other, though most contemporary researchers consider these constructs to be conceptually distinct [@timms2012burnt; @kim_burnout_2009; @goering2017not; @schaufeli2008workaholism; @trogolo2020work]. @goering2017not, for example, explored nomological networks, concluding that the two constructs have a moderate (negative) association, but also distinct nomological networks. @schaufeli2008workaholism investigated both internal and external association indicators, concluding that engagement and burnout (as well as *workaholism*) should be considered distinct constructs.  

[^burn]: Burnout is a psychological syndrome consisting of exhaustion, cynicism, and inefficacy [see, for example, @leiter_areas_2004].

## Engagement as an attitude

@staw_employee_1994 investigated the relationships between *positive emotions* and favorable work outcomes, and, although they do not explicitly mention the word "engagement", their distinction between felt and expressed emotion likely held influence upon the burgeoning interest in the engagement construct. Clear in this history is the conceptualization of engagement as a work *attitude*. @kahn1990psychological defines engagement as "the harnessing of organization members' selves to their work roles; in engagement, people employ and express themselves physically, cognitively, and emotionally during role performances" (p. 692). This definition of engagement as an attitude was also heavily influenced by @rosenberg_cognitive_1960's tripartite model of attitudes, which was popular in the 1990's. According to @rosenberg_cognitive_1960, attitudes are a molar construct with cognitive, affective, and behavioral dimensions. Although falling out of favor in the decades following its construction, interest in the tripartite model was revived by @kaiser_campbell_2019. The attitudinal perspectives of engagement eventually blended into perspectives that focused on exploring the engagement construct through the lens of other conceptually similar constructs [see, for example, @baumruk2004missing and @shaw2005engagement, who framed engagement in terms of one's cognitive and affective *commitment* to one's organization]. 

## Engagement's substantive elements

@schaufeli_uwesutrecht_2003's elemental description of engagement is perhaps the most contemporarily popular, likely at least partially a function of the popularity of their widely-available (in many different languages) measure, the Utrecht Work Engagement Scale (UWES). schaufeli_uwesutrecht_2003 define engagement as a "positive, fulfilling, work-related state of mind that is characterized by vigor, dedication, and absorption" (p. 74). Via their specification, vigor is described as high levels of energy and mental resilience while working. Dedication refers to being strongly involved in one's work and experiencing a sense of significance, enthusiasm, inspiration, pride, and challenge. Absorption is characterized by being fully concentrated and happily engrossed in one's work, whereby time passes quickly and one has difficulties with detaching oneself from work [@schaufeli_measurement_2002]. The dimension of absorption has been noted as being influenced in conceptual specification by [@csikszentmihalyi1990flow]'s concept of "flow".

## Existing Measures of Engagement

Our review of existing instruments non-exhaustively presents measures that are commonly viewed as *either* predominantly academic or applied, although please note that this is an imposed subjective distinction.  

### Research measures (e.g., freely available).

Multiple research scales currently exist in addition to the UWES mentioned above [@schaufeli_uwesutrecht_2003]. These additional measures include the Intellectual, Social, Affective (ISA) Engagement Scale [@soane2012development]. This 9-item measure draws inspiration from @kahn_psychological_1990's theory of engagement and can aggregate to three 3-item scales (Intellectual Engagement, Social Engagement, and Affective Engagement) or one 9-item summary aggregate (Overall Engagement). Intellectual engagement refers to the degree of intellectual absorption one has in their work and the degree they think about improving work [@soane2012development]. Social engagement primarily concerns social connections in a workplace context as well as having shared values with colleagues [@soane2012development]. According to @soane2012development, affective engagement refers to a positive emotional state relating to one's work role.  This measure has been explicitly validated at both the subscale and overall aggregate level  [@soane2012development]. 

Another example of an engagement measure comes from @saks_antecedents_2006, who splits engagement into two distinct entities: job engagement and organization engagement. This dichotomy largely results from @kahn_psychological_1990’s theory that an individual’s role is central to engagement. @saks_antecedents_2006 further posits that employees typically have more than one role, with the most important being their work role and their role as a member of an organization. The former role is specific to the employee’s job, while the latter is more broad and refers to the organization as a whole. Antecedents and consequences of this measure have been tested, with findings suggesting that perceived organizational support precedes both job and organizational engagement and that job satisfaction, organizational commitment, intent to quit, and organizational citizenship behaviors (OCBs) are consequences [@saks_antecedents_2006]. Recently the broader theoretical model underpinning the measure was revisited and revised to include several new antecedents (e.g. leadership, job demands, dispositional characteristics, etc.) leading to engagement as well as consequences (e.g. burnout, stress, health and well-being, etc.) resulting from high or low levels of engagement [@saks2019antecedents].

### Commercial measures (e.g., typically fee-based).

Gallup’s Q12 is a popular commercial measure for engagement. The Q12 is a 12-item measure that originated from a push to use “soft” metrics as opposed to “hard” ones for future action planning [@coffman_hard_1999]. In this interpretation “soft” metrics tend to be metrics that are more abstract and difficult to measure (e.g. engagement, brand loyalty), while “hard” metrics are easily-measured and typically deal with concrete numbers (e.g. turnover, profitability). In the original creation of the survey, each of the 12 items were found to relate to important organizational outcomes including productivity, profitability, turnover, and customer satisfaction [@coffman_hard_1999]. A recent meta-analysis of 456 studies revealed that the Q12 also relates to additional performance measures such as absenteeism, wellbeing, and organizational citizenship [@harter_relationship_2013]. While this engagement measure is one of the most popular, some scholars disagree with its conceptualization as “engagement”; some feel that this measure is better described as (or no different than) a measure of overall satisfaction, as the two concepts are highly correlated, *r* = .91 [@sirota2013enthusiastic]. 

Gallup is not the only organization with an engagement measure; many consulting companies have commercially available surveys, models, and processes for measuring engagement. One such example is Aon Hewitt, a consulting firm that annually measures engagement for over 1000 companies worldwide. Their measurements are centered around an engagement model that focuses on three main factors: say, stay, and strive. Essentially, the model states that employees demonstrate engagement through saying positive statements about their organization, staying at their organization for a long time, and striving to put in their best effort and help the organization succeed [@hewitt2017]. In their most recent analysis. @hewitt2017 recently noted that global levels of engagement may be declining as in this report they had retracted since the previous year.

BlessingWhite, another consulting firm, provides a different model for engagement. BlessingWhite's model, the X Model, measures engagement through the lens of satisfaction and contribution. Essentially, BlessingWhite believes that cooperation between the organization and individual employees is necessary, and that maximum engagement can only be reached when an employee reaches maximum levels of satisfaction while also outputting maximum contribution towards the organization [@blessingwhite2018]. Their model holds each level in the organization accountable for employee levels of engagement. From their view, executive leaders must shape the organization's culture, and managers must be able to effectively communicate with and motivate their subordinates [@blessingwhite2018]. 

The last commercial example discussed here[^vendors] is the Towers Perrin-ISR, which holds the philosophy that employee engagement can only be worked on indirectly; engagement can only be attained through effective leadership, business strategy, and organizational culture [@towersperrin2009]. Rather than focus on building an involved model for engagement, Towers Perrin-ISR instead focuses on leadership development and creating a healthy organizational culture. Through fulfilling these antecedents of engagement, @towersperrin2009 argues that employees will have a vivid understanding of organizational goals. In addition, employees will become committed to the organization and motivated to contribute. 

[^vendors]: This non-exhaustive list is not meant to be comprehensive. We intended to present some popular measures (albeit from larger vendors) in an attempt to capture the variety of rationales and purposes behind the creation and administration of these measures. 

## Our Measure of Engagement

Our theoretical conceptualization of work engagement is primarily informed by @schaufeli_uwesutrecht_2003 and @rosenberg_cognitive_1960. Theoretically, engagement is a mental state wherein employees: a) feel energized (*Vigor*), b) are enthusiastic about the content of their work and the things they do (*Dedication*), and c) are so immersed in their work activities that time seems compressed (*Absorption*). We further decompose each of these facets into three attitudinal components: d) feeling (e.g., affect), e) thought (e.g., cognition), and f) action (e.g., behavior). Regarding the distinction between "the job" and "the organization" as a referrent for engagement, our measure scatters indicators of both throughout, although we did not intentionally balance the measure with regard to the referent.  The current study's focus is on reaching a desired final set of 18 items, balancing the measure across our 3 (substantive) x 3 (attitudinal) dimensions with 2 items per "cell".

### Bifactor structures.

Methodologically, we have chosen to empirically model our measure via confirmatory factor analysis of a bifactor structure (aka bifactor analysis). Typically, bifactor analyses are utilized when exploring common method variance [@biderman2011ubiquity; @gade2017disentangling; @reise_rediscovery_2012], and the "bi" construct is a unidimensional specification (e.g., "one" construct/factor commonly interpreted as common method oriented). The current study extends this tradition, as two multi-dimensional factor structures specified *a priori* are simultaneously imposed. 

# Methods

We solicited three different samples for purposes of winnowing from 20 to 18 final scale items. One sample was a Prolific panel, one was a Qualtrics panel, and one was a "snowball" sample whereby friends and colleagues of the paper authors were invited to participate. In the snowball sample, invited individuals were also asked to further forward the survey along to friends and colleagues of theirs, with the "forwarding along" component being requested *ad infinitum*. 

## Participants

```{r getdata}

## Original script is "combined samples.R" in this folder

## Cleaning Qualtrics construct validation data - 10/14/21
## apparently different working paths for rmarkdown: https://here.r-lib.org/

newdata.att <- read.csv("..//Qualtrics//Engagement+(Attitudinal)_October+12,+2021_08.02.csv"); names <- newdata.att[1,c(1:92)] #[47:66]
newdata.sub <- read.csv("..//Qualtrics//Engagement+(Substantive)_October+12,+2021_08.01.csv")#[47:66]

newdata.att <- newdata.att[-c(1:2),]                      ## peskies
newdata.sub <- newdata.sub[-c(1:2),]

write.csv(newdata.att, "changingnumerica.csv")
newdata.att <- read.csv("changingnumerica.csv")            ## that worked!! 
write.csv(newdata.sub, "changingnumerics.csv")
newdata.sub <- read.csv("changingnumerics.csv") 

library(careless)
newdata.att$careless_long <- longstring(newdata.att[20:83])
newdata.sub$careless_long <- longstring(newdata.sub[20:83])
newdata.att$irv <- irv(newdata.att[48:51])
newdata.sub$irv <- irv(newdata.sub[55:58])

newdata.att$irv2 <- irv(newdata.att[25:28])   ## another reverse-score
newdata.sub$irv2 <- irv(newdata.sub[25:28])

## need filter for non-differentiating reverse-score people

newdata.att$flag <- "use"; newdata.sub$flag <- "use"         ## need to do because subset on lines 44/45 can't != "Flagged"
## upped time to 300 seconds as data still looked bad with 200

newdata.att$flag[newdata.att$careless_long > 12 | newdata.att$Duration..in.seconds. < 300 | newdata.att$irv == 0 | newdata.att$irv2 == 0]  <- "Flagged"
newdata.sub$flag[newdata.sub$careless_long > 12 | newdata.sub$Duration..in.seconds. < 300 | newdata.sub$irv == 0 | newdata.sub$irv2 == 0]  <- "Flagged"

newdata.att$flag <- as.factor(newdata.att$flag)
newdata.sub$flag <- as.factor(newdata.sub$flag)


useatt <- newdata.att[ which(newdata.att$flag == "use"), c(1:92)]
usesub <- newdata.sub[ which(newdata.sub$flag == "use"), c(1:92)]

useseb.sorted <- usesub[,c(1:47, 48:50,55:56,61:63,51:52,57:58,64:65,53:54,59:60,66:67,68:92)]
names(useseb.sorted) <- names(useatt)           ##### focal engagement is 48:67

qualtrics <- as.data.frame(rbind(useseb.sorted,useatt))      ## 377 out of 743 (51% retained)
                                                             ## engagement = 48-67
qualtrics.engage <- qualtrics[,c(48:67)]

qualtrics.engage <- data.frame(lapply(qualtrics.engage, function(x) as.numeric(as.character(x))))

################################################################################
################################################################################
################################################################################
################################################################################

## Prolific:    

temp <- read.csv("..//prolific data//initial_data_screen.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

x <- paste("item", sep="",1:404)
y <- t(temp[2,])
## decluttering Qualtrics excess
data <- temp[-c(1:3),]                                           ## Getting rid of all 3 weird Qualtrics rows
colnames(data) <- x

incomplete <- read.csv("..//prolific data//inprogress.csv", header=FALSE, na.strings="")   ## NOTE: 404 vars (9/28/21) make sure to check indexing used throughout script

data2 <- incomplete[-c(1:2),-c(10,12,16,113,199,285,371,379,400, 406:411)]                                          

data3 <- as.data.frame(cbind(data2$V8,data2$V9,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2$V1,data2))

colnames(data3) <- x

rm(x, y, temp)       

use <- rbind(data,data3)

## STILL NEED FILE WITH BAD RESPONDENTS IDENTIFIED (E.G., Item_18=2, na > 200, longstring > 20, CARELESS CHECKS > 1)

library(careless)
use$careless_long <- longstring(use[18:399])
use$missing <- rowSums(is.na(use[18:404])) 

use$flag <- NA

use$flag[use$item18 == 2 | use$careless_long > 20 | use$missing > 200] <- "Flagged"
use$flag[use$item61 == 5 & use$item145 == 5 & use$item248 == 2 & use$item308 == 3] <- "Good"

use2 <- use[which(use$flag == "Good"), ]
## descr::freq(use2$flag)                         ## no overlap - all "good" unflagged


prolific <- use2[,c(380:382,387:388,393:395,
                    383:384,389:390,396:397,
                    385:386,391:392,398:399)]     ## 568 out of 785 (72% retained)

names(prolific) <- names(qualtrics.engage)
prolific <- data.frame(lapply(prolific, function(x) as.numeric(as.character(x))))

######################################################################################################
######################################################################################################
######################################################################################################


## The sample was expanded via further snowball sampling with Eagle newbies on/about March 2022, with the additional sample (n=232; "Engagement(post-Qualtrics)April1920221118.csv")
## The current sample has 234 using choice text from Engagement_Pos Qual_2022-05-01_Choic Text.csv. Was pulled on May 1, 2022. 

snowball <- read.csv("..//Snowball Data//Engagement_Pos Qual_2022-05-01_Numeric Text.csv")[-c(1:2),c(47:66)]

snowball <- data.frame(lapply(snowball, function(x) as.numeric(as.character(x))))

##########################################################################
##########################################################################
##########################################################################

prolific$from <- "Prolific"
snowball$from <- "Snowball"
qualtrics.engage$from <- "Qualtrics"

together <- rbind(prolific, snowball, qualtrics.engage)

```

Of the `r (nrow(newdata.att)+nrow(newdata.sub))` total Qualtrics panel respondents, `r (nrow(newdata.att)+nrow(newdata.sub))-(nrow(qualtrics.engage))` were excluded based on conservative indices of carelessness across the larger survey (consistent non-differentiating responses across more than 20 consecutive items or greater than 50% missing responses). For Prolific panel respondents, `r nrow(prolific)` were retained of `r nrow(use)` total participants due to the same exclusion criteria. The smaller (*n* = `r nrow(snowball)`) snowball sample retained all participants for a total combined analysis sample of `r nrow(together)`.

## Procedure

A previous instrument administration reduced an initial list of 36 candidate items to 20 [@engage_2022]. Primarily for the goal of balance, we wanted to ultimately retain only 18 items (6 per attitudinal/substantive scale dimension, 2 per bifactor subscale). The items considered candidates for deletion were from bifactor subscales that yet retained 3 candidation items: the Absorption-Cognition subscale (Item 1: *I am able to concentrate on my work without getting distracted*, Item 3: *Time passes quickly while I'm working*, and Item 4: *I find it difficult to mentally disconnect from work*) and the Dedication-Cognition subscale (Item 25: *I plan to stay with this company as my career advances*, Item 26: *I believe this company cares about my career goals*, and Item 28: *This organization challenges me to work at my full potential*)[^numbers]. Two primary considerations were given to the decision to retain or delete the 6 deletion candidates: 1) is the content of the item necessary for the definitional integrity of the content domain, and 2) does the empirical functioning of the item implicate priority regarding deletion or retention.

[^numbers]: Item numbers presented throughout this presentation are legacy numbers from the initial 36-item pool of candidate indicators. 

# Results

We used `r cite_r("r-references.bib")` for all our analyses. 

```{r scalereduction, fig.cap="Bifactor analysis minus Item 4."}

## Drop candidates are 1,3,4 & 25,26,28

together$C14 <- 7-together$C14

cog <- psych::alpha(together[1:8])
aff <- psych::alpha(together[9:14])
beh <- psych::alpha(together[15:20])

abs <- psych::alpha(together[c(1:3, 9:10, 15:16)])
vig <- psych::alpha(together[c(4:5, 11:12, 17:18)])
ded <- psych::alpha(together[c(6:8, 13:14, 19:20)])

# cor(together[1:8], use="pairwise.complete.obs")   ## probably C4 gets axed
# psych::alpha(together[1:3])

# cor(together[c(1:3, 9:10, 15:16)], use="pairwise.complete.obs")


library(lavaan)

bifactor1 <-'
Absorption = ~C1  + C3  + C4  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C4  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'


bifactor4 <-'
Absorption = ~C1  + C3  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'
## Oops bifactor1 actually has all 20 items in it - below is new 19-item bifactor1

bifactor1.new <-'
Absorption = ~C3  + C4  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C3  + C4  + C14 + C16 + C25 + C26 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

Fit.mod1 <- lavaan::cfa(bifactor1, data = together, missing = "ML", estimator = 'MLR')
Fit.mod4 <- lavaan::cfa(bifactor4, data = together, missing = "ML", estimator = 'MLR')
Fit.mod1.new <- lavaan::cfa(bifactor1.new, data = together, missing = "ML", estimator = 'MLR')

# semPlot::semPaths(Fit.mod2, bifactor = c("Cognitive", "Affective", "Behavioral"), "std", layout = "tree3",
#                  rotation = 2, curvePivot=TRUE, style="lisrel", nCharNodes = 0, pastel=FALSE)

#semPlot::semPaths(Fit.mod4, bifactor = c("Cognitive", "Affective", "Behavioral"), style="lisrel", "std", layout = "tree3", rainbowStart=.5,sizeLat=10, rotation = 2, sizeMan=4.5,edge.label.cex=0.75, asize=2)

stand1 <- standardizedSolution(Fit.mod1)
fit1 <- fitMeasures(Fit.mod1)

stand4 <- standardizedSolution(Fit.mod4)
fit4 <- fitMeasures(Fit.mod4)

stand1.new <- standardizedSolution(Fit.mod1.new)
fit1.new <- fitMeasures(Fit.mod1.new)

```

```{r 19to18, fig.cap="Bifactor analysis final 18-item scale(s) definitions.", fig.height=8}

## Empirically 25 has lowest corrected item-totals with both attitude (cognition) and substantive (dedication), however, these are marginal and the CONTENT of 26 and 28 are a bit redundant, so we would like to retain 25 and drop either 26 or 28


bifactor_28 <-'
Absorption = ~C1  + C3  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C28 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C14 + C16 + C25 + C28
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'

bifactor_26 <-'
Absorption = ~C1  + C3  + A5  + A8  + B10 + B11
Vigor      = ~C14 + C16 + A17 + A19 + B21 + B22
Dedication = ~C25 + C26 + A31 + A32 + B34 + B35
Cognitive  = ~C1  + C3  + C14 + C16 + C25 + C26
Affective  = ~A5  + A8  + A17 + A19 + A31 + A32
Behavioral = ~B10 + B11 + B21 + B22 + B34 + B35
Absorption ~~ 0*Affective
Absorption ~~ 0*Behavioral
Absorption ~~ 0*Cognitive
Vigor      ~~ 0*Affective
Vigor      ~~ 0*Behavioral
Vigor      ~~ 0*Cognitive
Dedication ~~ 0*Affective
Dedication ~~ 0*Behavioral
Dedication ~~ 0*Cognitive
Dedication ~~ 1*Dedication
'


Fit.26 <- lavaan::cfa(bifactor_26, data = together, missing = "ML", estimator = 'MLR')
Fit.28 <- lavaan::cfa(bifactor_28, data = together, missing = "ML", estimator = 'MLR')

semPlot::semPaths(Fit.26, bifactor = c("Cognitive", "Affective", "Behavioral"), style="lisrel", "std", layout = "tree3", rainbowStart=.5,sizeLat=10, rotation = 2, sizeMan=4.5,edge.label.cex=0.75, asize=2)

#semPlot::semPaths(Fit.28, bifactor = c("Cognitive", "Affective", "Behavioral"), style="lisrel", "std", layout = "tree3", rainbowStart=.5,sizeLat=10, rotation = 2, sizeMan=4.5,edge.label.cex=0.75, asize=2)

stand3 <- standardizedSolution(Fit.26)
fit26 <- fitMeasures(Fit.26)

stand4 <- standardizedSolution(Fit.28)
fit28 <- fitMeasures(Fit.28)

```

Looking first at the Absorption-Cognition candidate items (1, 3, and 4), Item 4 stood out as a candidate for exclusion based on empirical indices (corrected item-total correlations, inter-item correlations, and bifactor analysis fit; $\chi^2_{with4}$ = `r fit1.new[3]`, $\chi^2_{without4}$ = `r fit4[3]`). Conceptually we also agreed that Item 4 was not uniquely critical for comprehensive coverage across either the Cognition or Absorption constructs. 

Regarding candidate items 25, 26, and 28, item 25 exhibited the weakest corrected item-total correlation for both the Dedication (*r* = .69) and Cognition scales (*r* = .60), however, the relative magnitudes were moderately high, coefficients for all three items were comparable (ranging from .60 to .78) and the item 25 content was deemed critical for both the Cognition as well as Dedication content domains. Two different CFAs were performed with comparable fit indices - one retaining only item 26 ($\chi^2_{keep26}$ = `r fit26[3]`), and the other instead retaining item 28 ($\chi^2_{keep28}$ = `r fit28[3]`). 

Ultimately the definitional uniqueness of item 26, focusing on percieved reciprocity and support regarding tenure/career objectives led to a decision for retention. This entire scale reduction endeavor, therefore, concluded with the deletions of Item 4, "I find it difficult to mentally disconnect from work" and Item 28, "This organization challenges me to work at my full potential".  

```{r fitindicestable}

Final1.1 <- as.data.frame(fitMeasures(Fit.mod1))
Final1.4 <- as.data.frame(fitMeasures(Fit.mod4))
Final1.26 <- as.data.frame(fitMeasures(Fit.26))
Final1.28 <- as.data.frame(fitMeasures(Fit.28))
Final1.1.new <- as.data.frame(fitMeasures(Fit.mod1.new))


Model <- c("20 Item", "Retain 1", "Retain 4", "Retain 26", "Retain 28")
chisq <- round(c(Final1.1[3,1], Final1.1.new[3,1], Final1.4[3,1], Final1.26[3,1], Final1.28[3,1]),2)
df <-    round(c(Final1.1[4,1], Final1.1.new[4,1], Final1.4[4,1], Final1.26[4,1], Final1.28[4,1]),2)
RMSEA <- round(c(Final1.1[44,1], Final1.1.new[44,1], Final1.4[44,1], Final1.26[44,1], Final1.28[44,1]),2)
SRMR <-  round(c(Final1.1[58,1], Final1.1.new[58,1], Final1.4[58,1], Final1.26[58,1], Final1.28[58,1]),2)
CFI <-   round(c(Final1.1[17,1], Final1.1.new[17,1], Final1.4[17,1], Final1.26[17,1], Final1.28[17,1]),2)
TLI <-   round(c(Final1.1[18,1], Final1.1.new[18,1], Final1.4[18,1], Final1.26[18,1], Final1.28[18,1]),2)
AIC <-   round(c(Final1.1[38,1], Final1.1.new[38,1], Final1.4[38,1], Final1.26[38,1], Final1.28[38,1]),2)

fittable <- as.data.frame(cbind(Model,chisq, df, RMSEA, SRMR, CFI, TLI, AIC))

apa_table(
  fittable
  , caption = "Fit indices five different bifactor CFAs."
  , escape = TRUE
  , landscape = TRUE
  , note = "Items were dropped sequentially, the first CFA reflects 20 items, the next two CFAs reflect 19 items, and the last two CFAs reflect 18 items."
)


```

```{r itemstable}

items <- read.csv("modification indices KEY - Hopefully Final.csv")  ## without 4

apa_table(
  items
  , caption = "Suggested final scale definitions."
  , escape = TRUE
  , landscape = TRUE
  , note = "The recommended response scale is 'Strongly Disagree', 'Disagree', 'Somewhat Disagree', 'Somewhat Agree', 'Agree', and 'Strongly Agree'"
)

```

Figure \@ref(fig:19to18) presents the visual bifactor CFA for the final scale definitions, Table \@ref(tab:fitindicestable) presents a more comprehensive table of fit indices across five different bifactor analyses, and Table \@ref(tab:itemstable) presents the final recommended measure regarding the 18-item scale, including the individual item stems and response options. 

# Discussion

We believe that this project has theoretical, methodological, and practical implications. By specifying known sources of item covariance (through *a priori* specification of alternative factors), it is possible that we may help explain some of the high inter-scale correlations that have been reported with other measures of engagement. We do this via extension of the bifactor analsis tradition, which historically has been used in common method variance investigations where only "one" alternative factor is specified. Although not common in the literature, we hope that this type of extension of bifactor analyses may be further pursued and investigated. 

Our primary aspiration for developing this measure was that it would be a public domain instrument that would draw equal appeal from both practitioners and academics. These preliminary investigations suggest that it is scalable to two aggregations which we have been referring to as: 1) research (DAC), and 2) actionable (ABC). Our (as-of-yet untested) assumption is that practitioners may be more interested in feedback regarding how their employees *think*, *feel*, and *behave* with regard to engagement. Academics, on the other hand, may be more interested in possible differentiation between levels of dedication, absorption, and vigor. Having one assessment that may aggregate to either framework not only addresses the demand of constituent users, but it also facilitates aggregation across samplings for broader purposes such as norms development, validation, and metaanalysis.

Further detail regarding the development, history, and construct and criterion-related validation of this measure is available at other SIOP 2023 sessions.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
